# 内核态处理快速路径

决赛开始后，异步的切换速度优势并没有显现。RUST的异步优化不成熟，很多可以优化的状态并没有优化。

无栈异步是异步编程的未来。如今有众多的有栈异步和无栈异步的性能对比，无栈异步通常能够以3倍以上的切换速度优势胜出。但我们的测试结果是反过来的，因为对于系统调用，它在大多数情况下是用户态和内核态之间的切换，进程之间的切换次数是非常少的。在这种场景下，每一个await都会导致和它属于同一个作用域的变量被放置在内存而不是寄存器中，即显著降低了寄存器的使用率，这对于拥有大量寄存器的RISCV架构尤其明显。第二，目前异步函数的内联并不完全，每一次异步函数的调用都会产生实打实的开销，而不能如同步函数一样使用非常成熟的零开销内联优化。

## 让内核态与用户态的切换更快

我们知道，callee saved寄存器（s0-s11）是由被调用者保存的，当一个符合调用规范函数返回后，这些寄存器保证不会发生变化。如果把内核态的处理过程符合函数调用规范，那么当它回到用户态的时候，这些callee saved寄存器不会改变，我们似乎没有必要保存这些寄存器。

听起来非常不错对不对？这样一下子就可以降低24个时钟的系统调用开销（load+store）。然而没有这么简单，因为这些寄存器可能会被内核使用，例如fork系统调用，他需要把这些寄存器复制给新的线程。例如信号处理，这些寄存器需要被保存下来并压在栈上。如果我们不把这些寄存器写入内存，那么内核就无法拿到这些寄存器的数据。

### 内核态的二次重入

FTL OS对这个问题进行了深入探索。早在初赛开始之前，FTL OS针对fork等系统调用提出“二次重入”的内核态切换方式，即把内核态的处理过程分为两个部分，第一个部分不会保存callee-saved寄存器，第二个部分才会保存这些寄存器。如果第一个部分已经可以完成处理那么根本不需要进入第二个流程，速度就这样快起来了。

当时FTL OS还没有使用无栈异步架构。如今我们可以让无栈异步架构运行在第二部分上，把第一部分称为快速系统调用路径，而它运行在同步上下文。

![image-20220526005049320](D:/University/OS competition/ftl-os/doc/pic/进程调度-快速路径.png)

从异步上下文可以直接进入用户态；但从用户态进入陷阱时会先进入快速处理路径，如果快速处理路径可以完成处理将直接回到用户态，如果无法处理将回到异步上下文。这种方式下保存用户寄存器于保存异步上下文寄存器被拆分到了用户态与快速处理路径的跳转和快速处理路径与异步上下文的跳转，没有额外的寄存器开销。对于如`getpid`等系统调用，快速处理路径可以避免大量不必要的callee saved寄存器加载与保存。

## 快速处理路径的内核栈

二次重入路径提出时，FTL OS认为每个线程都需要为快速处理路径分配一个内核栈。但事实上这是不需要的，我们完全可以复用异步上下文所运行的栈，让整个操作系统依然运行在初始栈上。快速处理路径是同步的，不会在任何地方发生中断之外的上下文切换，它必须完全返回后再进入异步上下文。

在这种设计思路下，快速处理路径运行时无法切换到另一个进程，因此栈上的信息完全没有保存的必要，可以复用异步上下文的栈，如同内核态中断时一般。

## trampoline

trampoline是用户态进入内核态的入口，也是调用快速处理路径之处。从用户态角度看，它的运行过程是这样的：

* 进入内核态
* 保存caller-save寄存器
* 调用快速处理函数，获取返回值
* 判断返回值，有两种可能：
  * 执行成功，加载caller-save寄存器，返回用户态，结束
  * 执行失败，继续往下
* 保存callee-save寄存器
* 执行失败，进入异步处理过程
* 异步处理过程结束，加载全部寄存器，返回内核态

看起来很乱对不对？事实上FTL OS的trampoline是以内核态的视角设计的，它的运行过程是这样的：

* 这里是异步调用函数，它准备进入用户态了！
* 进入trampoline
* 保存内核态的callee-save寄存器，加载用户态的全部寄存器并切换环境，进入用户态
* 从用户态返回到trampoline
* 保存用户态的caller-save寄存器，sp，加载内核态sp，切换到内核态环境
* 调用快速处理路径函数
* 判断返回值，有两种可能：
  * 执行成功，加载caller-save寄存器并切换环境，返回用户态
  * 执行失败，继续往下
* 保存用户态的callee-save寄存器，加载内核态的callee寄存器
* 通过ret返回，回到异步上下文

FTL OS中用户态就是内核态调用了一个函数，因此快速处理路径也是内核态调用的一个函数。

## 让系统调用更快

rCore基于match的系统调用看起来没什么问题，但回想xv6实验，C语言没有match，是怎么进行系统调用的？没错，它在静态区放置了一个数组，里边放置了一系列函数指针。系统调用时根据调用号从数组中取出对应的函数指针，并直接运行。

哪种方式更好？我们可以看看编译器会如何处理两种情况。如果你使用match，它会编译为一个跳转表，即根据调用号在跳转表中获取一个目的地址，然后直接跳过去。

看起来跳转表和函数指针数组差不多。但指针数组应该会更快，因为rust编译器认为match里面每个分支的函数调用规范是不相同的，因此必须把压栈过程放入每一个跳转地点，即函数调用的过程经过了：从跳转表中查询目的地址，跳到目的地址，压栈，函数调用的四个过程，并产生两次几乎无法避免的分支预测错误。对于函数指针数组，我们只需要查询目的地址，压栈，函数调用三个过程，只有一次分支预测错误，还节约了指令缓存。

rCore-tutorial直接把系统调用的参数放在了函数参数上，而且每个函数的参数个数与类型都不相同。这直接导致了每个函数都具有不同的调用方式，让match成为了唯一的选择。FTL OS在函数内部获取参数，因此所有函数的签名都是一样的，因此函数指针数组的方式就变得可行了。但对于异步函数，match仍然是最方便的方法，因为每个异步函数返回的future具有不同的大小，函数签名也各不相同。解决方法也是存在的，就是使用arena方式预分配异步运行空间。

## arena的异步多态

我们知道，`dyn trait`是rust实现多态接口最方便的方法。但`dyn trait`并没有提供async接口，想想也能明白，每一个future都具有不同的大小，具有不同的类型，无法进行动态分发。因此我们需要对future进行类型擦除，即使用`Pin<Box<dyn Future<Output=...>>>`的方式来让异步函数具有同一个接口，它需要一次缓慢的内存分配，而内存分配的时间很可能比异步函数运行的时间还要长。

arena通过舍弃异步函数节约内存的优势来让它在多态上下文跑得更快。arena是一种提前为异步函数分配空间的方式，使用它我们就可以把异步函数返回的`Futue`放在提前分配好的地方，完全解决内存分配太过缓慢的问题。arena相当于一个异步上下文的栈，必须比异步函数更大，这就毁掉了异步函数节约内存的优势。目前FTL OS的主循环future的大小仅为1.5 KB，这对于栈空间是不可想象的。