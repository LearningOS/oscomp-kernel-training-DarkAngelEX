# 锁

FTL OS实现了自旋排他锁，自旋共享锁，睡眠排他锁，睡眠共享锁四种锁，分别应用在不同的场景。

## 自旋排他锁

FTL OS的自旋排他锁实现非常简单，核心代码如下：

```rust
// ftl-uitl/src/sync/spin_mutex.rs
fn obtain_lock(&self) {
    while self.lock.compare_exchange(false, true, Ordering::Acquire, Ordering::Relaxed).is_err() {
        while self.lock.load(Ordering::Relaxed) {
            core::hint::spin_loop();
            ... // deadlock detect
        }
    }
}
fn drop(&mut self) {
    self.mutex.lock.store(false, Ordering::Release);
    S::after_unlock(&mut self.guard);
}
```

`obtain_lock`使用CAS操作更新原子变量`lock`，当值为false时原子地修改为true，这是自旋锁实现的通用方法。`drop`函数中将`lock`写入false，这两处代码是唯一会修改`lock`字段的代码，而当`lock`为true时obtain_lock无法修改`lock`，因此析构函数对`lock`的修改一定会被`obtain_lock`观测到。CAS操作失败时执行的等待操作为普通的访存，自旋等待时不会如CAS操作一样反复广播原子操作导致性能下降。FTL OS设计上不存在长时间占有的自旋锁，需要长时间占有对象应该由睡眠锁保护。因此FTL OS在自旋次数过多时将触发panic，这意味着内核发生了死锁。

## 自旋读写锁

FTL OS自旋读写锁是读者优先锁，状态定义如下：

|   lock的值    |                 定义                 |
| :-----------: | :----------------------------------: |
|     -2^31     |                非法值                |
|    -2^31+1    | 读写锁被写者占有，没有正在等待的读者 |
| [-2^31+2, -1] |  读写锁被写者占有，有正在等待的读者  |
|       0       |              锁未被占有              |
|  [1, 2^31-1]  |  读写锁被读者占有，数量等于lock的值  |

FTL OS的读者在获取读锁时会直接使用`fetch_add`操作将lock的值增加1，即使锁处于写锁状态也进行操作，然后才等待写者将锁释放。这样的实现相比在写者释放后进行原子操作将原子开销隐藏在了写者占有锁的时间段内。相比于排他锁，读写锁可以为读者提供更高的并行度，但释放锁时也需要一次原子操作，两者开销需要权衡。

## 睡眠锁

自旋锁可以在多核环境下有效保护数据的安全，但在竞争严重的环境下会导致CPU资源的极大浪费。而睡眠锁在获取锁失败时将出让CPU，可以有效地提高CPU资源的利用率。为了深度融合rust的async架构，FTL OS自行实现了异步睡眠锁，当睡眠锁结束占用自动唤醒下一个等待的任务，唤醒顺序严格等于提交顺序，且运行时不需要分配任何内存。

睡眠锁包含三个部分：睡眠锁本体，睡眠锁等待器，睡眠锁追踪器。等待器和追踪器对应了睡眠锁上锁的两个阶段：等待阶段和持有阶段。而等待阶段也被划分为了两个部分：初始化阶段和唤醒阶段。在初始化阶段睡眠锁将产生一个等待器，如果在初始化时睡眠锁处于上锁状态，等待器会将自身注册到睡眠锁的等待队列中并出让CPU。当持有睡眠锁的任务释放它的追踪器时会从睡眠锁等待队列中唤醒一个任务。被唤醒的任务将进入持有阶段，获取睡眠锁追踪器并释放等待器。相比于Linux的睡眠锁，FTL OS在唤醒阶段不需要获取睡眠锁的链表锁，被误唤醒时开销极小。

![image-20220525174301441](pic\锁1.png)

为了实现不需要额外分配内存的睡眠锁，睡眠锁将等待器放置在“逻辑栈”上。所谓“逻辑栈”是因为等待器跨越了`await`，空间被分配在了等待器所属`Future`的堆上，但我们依然可以将它看作在“逻辑栈”上，它所需的内存在所属`Future`分配内存时被一同分配了，没有额外内存分配。

等待器上包含一个侵入式链表节点，初始化时链表节点将会添加到睡眠锁等待队列的链表末尾。等待器上还携带了表示是否允许运行的标志位，这个标志位可能在初始化时被设置为true表示睡眠锁为空，不需要阻塞，但如果初始化时被设置为false，那么它只能被离开睡眠锁的任务设置为true。为了能够被释放锁的任务唤醒，等待器上还放置了自身的唤醒器，使用唤醒器可以将对于任务加入调度队列。需要注意的是等待器获取锁后就析构了，其他任务再获取它的任何数据都是极为危险的，而等待器能够析构的标志就是运行标志位，因此所有涉及唤醒任务内存的操作都需要在标志位修改之前进行。因此唤醒器需要在标志位修改之前取出。但任务的唤醒必须在标志为true之后，否则由于确实内存序限制，被唤醒任务执行poll时可能依然观测到运行标志位为false导致唤醒失败，任务丢失，而这又导致此睡眠锁死锁，而睡眠锁是无法用尝试次数的方式来发现死锁的。正确的方式是在标志位修改之前取出唤醒器，之后修改标志位，最后再用唤醒器唤醒对应任务。FTL OS调度器保证了如果任务被唤醒时处于运行状态，任务结束运行状态时会被再次放入调度器，不会导致任务丢失。

## 内存序

存粹的原子指令只能保证自身的修改在多核上是原子的，但被两次原子指令包围的起来的访存操作是如何保证在多核可见的呢？这就涉及了内存序。C++20标准定义了如下内存序：

| 内存序  | RISC-V 实现  |                             描述                             |
| :-----: | :----------: | :----------------------------------------------------------: |
| relaxed |    (NULL)    |                      不对访存作任何约束                      |
| acquire | fence r, rw  |             禁止之后的所有写操作被重排序在此之前             |
| release | fence rw, w  |             禁止之前的所有写操作被重排序在此之后             |
| consume | fence r, rw  | 类似acquire，但只对release的数据依赖链生效，不作用于全部访存 |
| acq_rel |  fence.tso   |               同时具有acquire和release的内存序               |
| seq_cst | fence rw, rw |   在满足acq_rel内存序的同时使之前的所有写操作在多核间可见    |

除了relaxed内存序外所有内存序都禁止了读操作重排序与CPU内部相关数据的乱序执行。需要注意的是单独使用acquire或release并不能保证数据的安全性，只有release-acquire结合使用才能保证数据操作是安全的。

CPU是如何保证所有写操作在多核间可见的？多核CPU采用**MESI缓存一致性协议**，每个缓存块都有无效、独享、修改、共享四种状态。独享状态的数据和内存是一致的，当其他CPU读取时会变为共享状态，发生写入时变为修改状态。修改状态缓存的数据与内存是不一致的，当其他核进行读操作时会写回主存并转变为独享状态。共享状态的数据被多个缓存持有并和主存是一致的，只要任何CPU修改了缓存，其他CPU对应的缓存都变为无效状态。MESI保证了任意数据的写入都能够在未来被所有其他的核心观测到，而内存序对应的内存屏障为状态的更新提供了顺序保证。

MESI协议的操作单位是cache-line，绝大多数平台上这一大小为64字节，这导致了被称为**伪共享**(false share)的性能下降现象。处于同一个cache-line的对象会共享缓存状态，因此当共享对象被其他核修改时整个cache-line都会失效，例如一个数组中每个单元都属于各自的CPU，CPU在各自单元上的操作理论上的互不影响的，但由于共享了cache-line会导致大量的cache失效，在高频CPU上会导致5倍以上的性能损失。更常见的例子是引用计数，由于引用计数是于数据一起放置的，因此每次引用计数的更新都会导致对象cache失效。为了避免伪共享，线程局部对象需要对齐至cache-line。

Hifive Unmatched使用的U74核心只有一个访存端口的顺序处理器，但这不意味着内存序不会出错。包括U74在内的多核CPU采用了如下的两种方式来提高性能：

* 写缓冲区（Store Buffer）。MESI协议的写操作将等待其他CPU的确认信息，在这期间写操作将被阻塞。为了避免阻塞影响到CPU，所有store操作会先提交至写缓冲区，在之后的适当时机才会写入cache与内存，而只有写缓冲区满时才会阻塞CPU。写缓冲区避免了写操作导致的频繁CPU暂停，但也导致在其他核心看来这个写操作被延迟了，如果延迟至了某条load之后就产生了store-load乱序。release内存序生成的屏障指令可以阻止它的发生，`fence r, rw`执行后的任何访存操作会等待写缓冲区清空，保证其他核心的观测顺序。
* 失效队列（Invalid Queue）。MESI协议的读操作需要等待其他CPU导致的缓存行被清空后再执行，在这期间读操作将被阻塞。引入失效队列后CPU的读操作不再被阻塞，其他CPU发送的缓存行无效信息将立刻回复并加入失效队列，在未来的适当时机再刷入cache。失效队列能有效提高其他CPU写操作的速度与当前CPU读操作的速度，但也导致了load-load与load-store乱序。acquire内存序生成的屏障指令可以阻止它的发生，`fence r, r`之后的访存操作将阻塞等待失效队列处理完成，保证cache和内存中的数据是相同的。

store-store乱序不会发生在顺序处理器，在乱序处理器中屏障指令可以防止store被乱序发射至写缓冲区。原子指令不保证清空写缓冲区和失效队列，不能保证前后的指令内存序正确，因此保护数据必须依赖内存屏障。

