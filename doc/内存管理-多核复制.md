# 多核复制

在操作系统中，遍地都是复制，最常见的就是从一个4KB的共享页复制到一个新的地址空间。这个操作的开销是如此地大，不仅耗时极高，还会直接毁掉L1 cache，显著降低后续操作速度。是否可以用多核来加速复制呢?让空闲的CPU来做这件事最好不过了。但涉及多线程就会和同步相关，必须使用原子操作来同步。

FTL OS实验性地引入了多核复制方法来加速内存复制。在复制之前会检测CPU是否存在空闲的CPU。如果不存在就使用普通的复制方法。

一次原子操作的开销约为40条指令，可以复制300字节。如果我们把4KB拆成4部分并均摊给4个CPU，那么复制的延迟约为复制2200字节，速度提升了一倍。我们可以用两个原子变量来实现复制的同步，第一个用来让其他CPU争抢复制权限，第二个用来标示完成复制的数量。提交复制申请的CPU会通过第一个原子变量提交申请，并通过第二个原子变量等待复制的完成，在等待的过程中它自身也可以进行复制。

## qemu测试

FTL OS实现了无锁多核复制的基本设施，只需要略微修改就可以上线，源代码位于`kernel/src/tools/mod.rs`中。但在决定上线之前还需要进行实际性能测试。

分别使用32个4KB的内存块作为源内存和目的内存，将CPU数，切片数量作为变量，进行10000次测试。由于主机CPU频率不稳定以及qemu编译缓存等原因，结果可能发生波动，因此人工忽略部分测试结果。

| CPU数量 | 切片数 | qemu吞吐量(MB/S) | windows吞吐量(MB/S) |        注释         |
| :-----: | :----: | :--------------: | :-----------------: | :-----------------: |
|    1    |   1    |     223-234      |      2900-3400      | 使用copy_from_slice |
|    1    |   1    |     203-215      |      2800-3200      |  使用多核复制系统   |
|    1    |   2    |     209-216      |      2600-2800      |  使用多核复制系统   |
|    2    |   2    |     184-261      |      2800-4600      |  使用多核复制系统   |
|    4    |   2    |     213-268      |      2700-3600      |  使用多核复制系统   |
|    1    |   4    |     186-210      |      2400-2600      |  使用多核复制系统   |
|    2    |   4    |     240-450      |      2300-3800      |  使用多核复制系统   |
|    4    |   4    |     220-587      |      2700-4730      |  使用多核复制系统   |
|    1    |   8    |     211-214      |      2500-2700      |  使用多核复制系统   |
|    2    |   8    |     217-362      |      2600-3200      |  使用多核复制系统   |
|    4    |   8    |     199-606      |      2600-3900      |  使用多核复制系统   |

在测试的时候，qemu呈现一种诡异的第一次最快，随后速度下降再上升的速度曲线，最慢的时候即使是单线程也能降低到20MB/s以下，因此使用qemu来分析性能是不合理的。但可以看到，当大多数核心都属于空闲状态时，多线程复制可以极高地提高复制吞吐量，而即使在单线程运行时也只会略微降低效率。

在真实平台上多核复制是否能运行得更快呢？将代码搬运到windows上进行测试，可以发现多线程复制系统出现了负优化，似乎这个优化并不能达到预想的性能，看来4KB的大小对于复制来说还是太小了。性能也可能受限于L3缓存的速度，因为x86-64会使用向量操作复制内存，单核就可以跑满总线带宽。而且如果要让多核复制维持工作，我们需要维持其他的CPU处于工作状态，这会显著增加平台功耗，并在一定程度上影响内存性能。在这个结果下，FTL OS的多核复制系统没有上线，但留下了基础设施。多核复制或许可以在缺页预测上发挥威力，提前读取预测缺页的页面，并将开销转移给其他的CPU。

